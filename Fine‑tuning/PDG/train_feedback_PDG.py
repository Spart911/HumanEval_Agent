import os
import ast
import torch
import networkx as nx
import subprocess
from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments
from peft import LoraConfig, get_peft_model
from torch.utils.data import Dataset
import gc

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ parallelism
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ---------------- 1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ----------------
LOCAL_MODEL_DIR = "/home/nyuroprint/Jupyter/Qwen2.5-Coder-3B"  # –ü–∞–ø–∫–∞ —Å —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
MAX_LEN = 512
EPOCHS = 2
BATCH_SIZE = 1
LR = 5e-6
OUTPUT_DIR = "./pdg_feedback_trained_github"
LIMIT = 10000

REPOS = [
    "https://github.com/psf/requests.git",
    "https://github.com/pallets/flask.git",
    "https://github.com/pandas-dev/pandas.git",
    "https://github.com/numpy/numpy.git",
    "https://github.com/scipy/scipy.git",
    "https://github.com/scikit-learn/scikit-learn.git",
    "https://github.com/matplotlib/matplotlib.git",
    "https://github.com/plotly/plotly.py.git",
    "https://github.com/pytorch/pytorch.git",
    "https://github.com/tensorflow/tensorflow.git"
]

CLONE_DIR = "./github_repos"
os.makedirs(CLONE_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
if not os.path.exists(LOCAL_MODEL_DIR):
    print(f"‚ùå –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ø–∞–ø–∫–µ: {LOCAL_MODEL_DIR}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞ –≤ —ç—Ç—É –ø–∞–ø–∫—É")
    exit(1)
else:
    print(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤: {LOCAL_MODEL_DIR}")

# ---------------- 2. –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ ----------------
print("üìÅ –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏...")
for repo in REPOS:
    repo_name = repo.split("/")[-1].replace(".git", "")
    dest = os.path.join(CLONE_DIR, repo_name)
    if not os.path.exists(dest):
        print(f"Cloning {repo} ‚Ä¶")
        try:
            result = subprocess.run(
                ["git", "clone", "--depth", "1", repo, dest],
                capture_output=True,
                text=True,
                timeout=300
            )
            if result.returncode != 0:
                print(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º {repo}: {result.stderr}")
            else:
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω {repo}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è {repo}: {e}")

# ---------------- 3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ PDG (Program Dependence Graph) ----------------
# PDG = AST nodes + control-flow edges (CFG-like) + data-flow edges (DFG-like)

def build_pdg_from_ast(tree: ast.AST, graph: nx.DiGraph):
    """
    –°—Ç—Ä–æ–∏—Ç PDG (Program Dependence Graph) –∏–∑ AST.
    graph -- networkx.DiGraph() ‚Äî —É–∑–ª—ã: label, type, name(opt)
    –ê–ª–≥–æ—Ä–∏—Ç–º:
      - –¥–æ–±–∞–≤–ª—è–µ–º AST-—É–∑–ª—ã (FunctionDef, If, For, Assign, Name, Constant, Call ...)
      - —Å–æ–∑–¥–∞—ë–º control-edges –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º–∏ ("next"), –∏–∑ —É—Å–ª–æ–≤–∏–π –≤ —Ç–µ–ª–∞ ("control")
      - —Å–æ–∑–¥–∞—ë–º data-flow edges: def -> use (–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å—Ç–µ–π—à–µ–π –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–∞—Ä—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π)
    –ó–∞–º–µ—á–∞–Ω–∏–µ: —ç—Ç–æ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∏ –ø—Ä–∞–≥–º–∞—Ç–∏—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è PDG, –ø—Ä–∏–≥–æ–¥–Ω–∞—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π/—Ñ–∏—á.
    """
    if "next_id" not in graph.graph:
        graph.graph["next_id"] = 0

    def new_id():
        nid = graph.graph["next_id"]
        graph.graph["next_id"] += 1
        return nid

    # –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –∫–∞—Ä—Ç—É –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–µ–∫—É—â–µ–π –æ–±–ª–∞—Å—Ç–∏
    def walk_block(statements, local_defs, prev_stmt_node=None):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ stmt, —Å–æ–∑–¥–∞—ë—Ç control 'next' edges –º–µ–∂–¥—É –Ω–∏–º–∏."""
        last_node = prev_stmt_node
        for stmt in statements:
            node_id = walk(stmt, local_defs)
            if node_id is None:
                continue
            # —Å–æ–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–º —Ä–µ–±—Ä–æ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä -> —Ç–µ–∫—É—â–∏–π (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
            if last_node is not None:
                graph.add_edge(last_node, node_id, label="next", type="control")
            last_node = node_id
        return last_node

    def walk(n, local_defs):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ AST-—É–∑–ª–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç node_id(–∏–ª–∏ —Å–ø–∏—Å–æ–∫ id –¥–ª—è –≤—ã—Ä–∞–∂–µ–Ω–∏–π)."""
        if n is None:
            return None

        # ---- Leaf nodes ----
        if isinstance(n, ast.Name):
            nid = new_id()
            ctx = "Load" if isinstance(n.ctx, ast.Load) else "Store" if isinstance(n.ctx, ast.Store) else type(n.ctx).__name__
            graph.add_node(nid, label=f"Name:{n.id} ({ctx})", type="Name", name=n.id, ctx=ctx)
            # –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–±—Ä–æ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ def->use
            if isinstance(n.ctx, ast.Load) and n.id in local_defs:
                graph.add_edge(local_defs[n.id], nid, label="def->use", type="data")
            return nid

        if isinstance(n, ast.Constant):
            nid = new_id()
            graph.add_node(nid, label=f"Const:{repr(n.value)}", type="Const")
            return nid

        # ---- Expressions ----
        if isinstance(n, ast.BinOp):
            left_id = walk(n.left, local_defs)
            right_id = walk(n.right, local_defs)
            op_id = new_id()
            op_name = type(n.op).__name__
            graph.add_node(op_id, label=f"BinOp:{op_name}", type="BinOp")
            for lid in (left_id, right_id):
                if lid is not None:
                    graph.add_edge(lid, op_id, label="operand", type="data")
            return op_id

        if isinstance(n, ast.UnaryOp):
            operand_id = walk(n.operand, local_defs)
            op_id = new_id()
            op_name = type(n.op).__name__
            graph.add_node(op_id, label=f"UnaryOp:{op_name}", type="UnaryOp")
            if operand_id is not None:
                graph.add_edge(operand_id, op_id, label="operand", type="data")
            return op_id

        if isinstance(n, ast.Call):
            func_id = walk(n.func, local_defs)
            call_id = new_id()
            graph.add_node(call_id, label="Call", type="Call")
            if func_id is not None:
                graph.add_edge(func_id, call_id, label="callfunc", type="data")
            for arg in n.args:
                aid = walk(arg, local_defs)
                if aid is not None:
                    graph.add_edge(aid, call_id, label="arg", type="data")
            for kw in getattr(n, "keywords", []):
                v = walk(kw.value, local_defs)
                if v is not None:
                    graph.add_edge(v, call_id, label=f"kw:{kw.arg}", type="data")
            return call_id

        # ---- Statements ----
        if isinstance(n, ast.Assign):
            # RHS value
            value_id = walk(n.value, local_defs)
            assign_id = new_id()
            graph.add_node(assign_id, label="Assign", type="Assign")
            if value_id is not None:
                graph.add_edge(value_id, assign_id, label="value", type="data")
            # targets
            for t in n.targets:
                if isinstance(t, ast.Name):
                    def_id = new_id()
                    graph.add_node(def_id, label=f"Def:{t.id}", type="Def", name=t.id)
                    graph.add_edge(assign_id, def_id, label="assign->def", type="data")
                    # –æ–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
                    local_defs = dict(local_defs)
                    local_defs[t.id] = def_id
                else:
                    # —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª–æ–∂–Ω—ã–µ targets (tuple, subscript, attr)
                    target_out = walk(t, local_defs)
                    if target_out is not None:
                        graph.add_edge(assign_id, target_out, label="assign->target", type="data")
            return assign_id

        if isinstance(n, ast.AugAssign):
            target_id = walk(n.target, local_defs)
            value_id = walk(n.value, local_defs)
            op_id = new_id()
            op_name = type(n.op).__name__
            graph.add_node(op_id, label=f"AugOp:{op_name}", type="AugOp")
            for src in (target_id, value_id):
                if src is not None:
                    graph.add_edge(src, op_id, label="operand", type="data")
            if isinstance(n.target, ast.Name):
                def_id = new_id()
                graph.add_node(def_id, label=f"Def:{n.target.id}", type="Def", name=n.target.id)
                graph.add_edge(op_id, def_id, label="result", type="data")
                local_defs = dict(local_defs)
                local_defs[n.target.id] = def_id
                return def_id
            return op_id

        if isinstance(n, ast.Return):
            val_id = walk(n.value, local_defs) if n.value else None
            ret_id = new_id()
            graph.add_node(ret_id, label="Return", type="Return")
            if val_id is not None:
                graph.add_edge(val_id, ret_id, label="ret", type="data")
            return ret_id

        if isinstance(n, ast.Expr):
            return walk(n.value, local_defs)

        if isinstance(n, ast.Compare):
            left_id = walk(n.left, local_defs)
            comp_id = new_id()
            graph.add_node(comp_id, label="Compare", type="Compare")
            if left_id is not None:
                graph.add_edge(left_id, comp_id, label="left", type="data")
            for op, comp in zip(n.ops, n.comparators):
                cid = walk(comp, local_defs)
                if cid is not None:
                    graph.add_edge(cid, comp_id, label="comp", type="data")
            return comp_id

        if isinstance(n, ast.If):
            # –£—Å–ª–æ–≤–∏–µ
            test_id = walk(n.test, local_defs)
            if_id = new_id()
            graph.add_node(if_id, label="If", type="If")
            if test_id is not None:
                graph.add_edge(test_id, if_id, label="cond", type="control")
            # —Ç–µ–ª–æ –∏ orelse –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –∫–æ–ø–∏—è–º–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
            body_defs = dict(local_defs)
            orelse_defs = dict(local_defs)
            # —Å–æ–∑–¥–∞—ë–º –ø—Å–µ–≤–¥–æ-—É–∑–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ç–µ–ª–∞/orelse (–¥–ª—è control-edges)
            body_start = None
            orelse_start = None
            # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º body
            prev = None
            for stmt in n.body:
                sid = walk(stmt, body_defs)
                if sid is not None:
                    if body_start is None:
                        body_start = sid
                    if prev is not None:
                        graph.add_edge(prev, sid, label="next", type="control")
                    prev = sid
            # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º orelse
            prev = None
            for stmt in n.orelse:
                sid = walk(stmt, orelse_defs)
                if sid is not None:
                    if orelse_start is None:
                        orelse_start = sid
                    if prev is not None:
                        graph.add_edge(prev, sid, label="next", type="control")
                    prev = sid
            # control-edges: if -> first stmt of body/orelse
            if body_start is not None:
                graph.add_edge(if_id, body_start, label="control_true", type="control")
            if orelse_start is not None:
                graph.add_edge(if_id, orelse_start, label="control_false", type="control")
            # Merge defs: –µ—Å–ª–∏ –æ–±–µ –≤–µ—Ç–≤–∏ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –æ–¥–Ω—É –∏ —Ç—É –∂–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é ‚Äî —Å–æ–∑–¥–∞—ë–º Merge node
            merged = dict(local_defs)
            for var in set(list(body_defs.keys()) + list(orelse_defs.keys())):
                b = body_defs.get(var)
                o = orelse_defs.get(var)
                if b and o and b != o:
                    merge_id = new_id()
                    graph.add_node(merge_id, label=f"Merge:{var}", type="Merge", name=var)
                    graph.add_edge(b, merge_id, label="merge", type="data")
                    graph.add_edge(o, merge_id, label="merge", type="data")
                    merged[var] = merge_id
                elif b:
                    merged[var] = b
                elif o:
                    merged[var] = o
            # –æ–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–∑—ã–≤–∞—é—â–µ–º—É —É—Ä–æ–≤–Ω—é
            local_defs.clear()
            local_defs.update(merged)
            return if_id

        if isinstance(n, ast.For) or isinstance(n, ast.While):
            loop_id = new_id()
            graph.add_node(loop_id, label=type(n).__name__, type=type(n).__name__)
            if isinstance(n, ast.For):
                target_id = walk(n.target, local_defs)
                iter_id = walk(n.iter, local_defs)
                if iter_id is not None:
                    graph.add_edge(iter_id, loop_id, label="iter", type="control")
                if target_id is not None:
                    graph.add_edge(target_id, loop_id, label="target", type="control")
            else:
                test_id = walk(n.test, local_defs)
                if test_id is not None:
                    graph.add_edge(test_id, loop_id, label="cond", type="control")
            # process body with copy of defs (we don't propagate body defs up to outer scope for simplicity)
            body_defs = dict(local_defs)
            prev = None
            for stmt in n.body:
                sid = walk(stmt, body_defs)
                if sid is not None:
                    if prev is not None:
                        graph.add_edge(prev, sid, label="next", type="control")
                    prev = sid
                    # connect loop header -> first body stmt
                    if prev is not None and loop_id is not None:
                        graph.add_edge(loop_id, prev, label="loop_body", type="control")
            return loop_id

        if isinstance(n, ast.FunctionDef):
            fid = new_id()
            graph.add_node(fid, label=f"Function:{n.name}", type="Function", name=n.name)
            # –∞—Ä–≥—É–º–µ–Ω—Ç—ã ‚Äî —Å—á–∏—Ç–∞—é—Ç—Å—è –¥–µ—Ñ–∞–º–∏ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏
            local = dict(local_defs)
            for arg in n.args.args:
                arg_id = new_id()
                graph.add_node(arg_id, label=f"Arg:{arg.arg}", type="Arg", name=arg.arg)
                local[arg.arg] = arg_id
                graph.add_edge(arg_id, fid, label="arg->func", type="data")
            # —Ç–µ–ª–æ: connect function node -> first stmt
            first = None
            prev = None
            for stmt in n.body:
                sid = walk(stmt, local)
                if sid is not None:
                    if first is None:
                        first = sid
                    if prev is not None:
                        graph.add_edge(prev, sid, label="next", type="control")
                    prev = sid
            if first is not None:
                graph.add_edge(fid, first, label="func->body", type="control")
            return fid

        if isinstance(n, ast.ClassDef):
            cid = new_id()
            graph.add_node(cid, label=f"Class:{n.name}", type="Class", name=n.name)
            local = dict(local_defs)
            prev = None
            first = None
            for stmt in n.body:
                sid = walk(stmt, local)
                if sid is not None:
                    if first is None:
                        first = sid
                    if prev is not None:
                        graph.add_edge(prev, sid, label="next", type="control")
                    prev = sid
            if first is not None:
                graph.add_edge(cid, first, label="class->body", type="control")
            return cid

        # Generic fallback: –ø—Ä–æ–±–µ–≥–∞–µ–º –≤—Å–µ –ø–æ–ª—è
        out = None
        for field, value in ast.iter_fields(n):
            if isinstance(value, list):
                for item in value:
                    if isinstance(item, ast.AST):
                        out = walk(item, local_defs) or out
            elif isinstance(value, ast.AST):
                out = walk(value, local_defs) or out
        return out

    # –Ω–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç–æ–π –∫–∞—Ä—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
    global_defs = {}
    # –ï—Å–ª–∏ –∫–æ—Ä–µ–Ω—å ‚Äî Module, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ —Ç–µ–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏ —Å—Ç—Ä–æ–∏–º control-next –º–µ–∂–¥—É stmt
    if isinstance(tree, ast.Module):
        walk_block(tree.body, global_defs, prev_stmt_node=None)
    else:
        walk(tree, global_defs)

    return graph


def extract_pdg_sequence(code: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É–∑–ª–æ–≤ PDG –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ '—Ç–µ–∫—Å—Ç'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º–∞—Ç–∞: Type[:name] Type[:name] ...
    """
    try:
        tree = ast.parse(code)
        graph = nx.DiGraph()
        graph.graph["next_id"] = 0

        build_pdg_from_ast(tree, graph)

        if len(graph.nodes) == 0:
            return ""

        # –ü–æ–ø—Ä–æ–±—É–µ–º —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å: —Å–Ω–∞—á–∞–ª–∞ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ü–∏–∫–ª—ã), –∏–Ω–∞—á–µ –ø–æ id.
        try:
            topo = list(nx.topological_sort(graph))
        except Exception:
            topo = sorted(graph.nodes())

        seq = []
        for nid in topo:
            node_data = graph.nodes[nid]
            t = node_data.get("type", "Unknown")
            name = node_data.get("name")
            if name:
                seq.append(f"{t}:{name}")
            else:
                seq.append(t)
        # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—á—Ç–æ–±—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –±—ã–ª–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–π)
        return " ".join(seq)
    except SyntaxError as e:
        # —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        return ""
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è PDG: {e}")
        return ""


def visualize_pdg_debug(code: str, filename: str):
    """
    –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è PDG ‚Äî –ø–µ—á–∞—Ç–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –ø–µ—Ä–≤—ã–µ –Ω–æ–¥-–ª–µ–π–±–ª—ã.
    """
    try:
        tree = ast.parse(code)
        graph = nx.DiGraph()
        graph.graph["next_id"] = 0
        build_pdg_from_ast(tree, graph)

        print(f"\nüîç PDG –¥–ª—è {filename}:")
        print(f"–£–∑–ª–æ–≤: {len(graph.nodes)}, –†—ë–±–µ—Ä: {len(graph.edges)}")

        # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 16 —É–∑–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        for i, (node_id, node_data) in enumerate(list(graph.nodes(data=True))[:16]):
            label = node_data.get("label", "")
            print(f"  {node_id}: {label}")

        # –ü–æ–∫–∞–∂–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ä—ë–±–µ—Ä (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ)
        print("–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–±–µ—Ä (source -> target : label):")
        for i, (u, v, ed) in enumerate(list(graph.edges(data=True))[:20]):
            print(f"  {u} -> {v} : {ed.get('label')} ({ed.get('type')})")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ PDG: {e}")


# ---------------- 4.1. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–∞/–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è ----------------

def get_compiler_feedback(path: str, run_timeout: int = 5) -> str:
    """
    –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
    –§–æ—Ä–º–∞—Ç: –∫–ª—é—á: —Å–æ–æ–±—â–µ–Ω–∏–µ (–±–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö —Å—Ç–µ–∫-—Ç—Ä–µ–π—Å–æ–≤, —Å—Ç–∞—Ä–∞–µ–º—Å—è —É–∫–æ—Ä–æ—Ç–∏—Ç—å).
    """
    parts = []

    # 1) –ö–æ–º–ø–∏–ª—è—Ü–∏—è –≤ –±–∞–π—Ç–∫–æ–¥ (py_compile)
    try:
        compile_proc = subprocess.run(
            ["python3", "-m", "py_compile", path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=run_timeout
        )
        stderr = compile_proc.stderr.strip()
        if stderr:
            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç—Ä–∞—Å—Å—ã ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 2 —Å—Ç—Ä–æ–∫–∏
            lines = stderr.splitlines()
            brief = " | ".join(lines[:2])
            parts.append(f"COMPILE_ERROR:{brief}")
    except subprocess.TimeoutExpired:
        parts.append("COMPILE_TIMEOUT")
    except Exception as e:
        parts.append(f"COMPILE_CRASH:{str(e)}")

    # 2) –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ (–≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ)
    try:
        run_proc = subprocess.run(
            ["python3", path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=run_timeout
        )
        stdout = run_proc.stdout.strip()
        stderr = run_proc.stderr.strip()
        if stdout:
            s = stdout.replace("\n", " \\n ")
            # —É–∫–æ—Ä–æ—Ç–∏–º –¥–æ 200 —Å–∏–º–≤–æ–ª–æ–≤
            parts.append("RUNTIME_OUT:" + (s[:200] + ("..." if len(s) > 200 else "")))
        if stderr:
            lines = stderr.splitlines()
            brief = " | ".join(lines[:3])
            parts.append("RUNTIME_ERR:" + (brief[:300] + ("..." if len(brief) > 300 else "")))
    except subprocess.TimeoutExpired:
        parts.append("RUNTIME_TIMEOUT")
    except Exception as e:
        parts.append(f"RUNTIME_CRASH:{str(e)}")

    if not parts:
        return "OK"
    return " ".join(parts)


# ---------------- 4. –°–±–æ—Ä Python —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ PDG ----------------

# ---------------- 5. –°–±–æ—Ä Python —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ PDG + –∫–æ–º–ø–∏–ª. –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ ----------------
texts = []
count = 0

print("üìÅ –°–±–æ—Ä Python —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ PDG + —Å–±–æ—Ä –∫–æ–º–ø–∏–ª. —Ñ–∏–¥–±–µ–∫–∞...")
for root, dirs, files in os.walk(CLONE_DIR):
    for file in files:
        if file.endswith(".py") and not file.startswith("test_"):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
            file_path = os.path.join(root, file)
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    code = f.read()

                pdg_sequence = extract_pdg_sequence(code)

                # —Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–±–æ–ª—å—à–µ N —Ç–∏–ø–æ–≤)
                if pdg_sequence and len(pdg_sequence.split()) > 20:
                    # —Å–æ–±–∏—Ä–∞–µ–º –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–Ω—É—é/—Ä–∞–Ω—Ç–∞–π–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
                    compiler_seq = get_compiler_feedback(file_path, run_timeout=3)

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—É—á–∞—é—â–∏–π —Ç–µ–∫—Å—Ç
                    # –§–æ—Ä–º–∞—Ç: PDG: ... COMPILER: ...
                    full_text = f"PDG: {pdg_sequence} COMPILER: {compiler_seq}"
                    texts.append({"content": full_text})
                    count += 1

                    # –î–ª—è –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    if count <= 3:
                        visualize_pdg_debug(code, file)
                        print(f"–ü—Ä–∏–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {pdg_sequence[:200]}...")
                        print(f"–ü—Ä–∏–º–µ—Ä compiler_seq: {compiler_seq}")

                if count % 50 == 0 and count > 0:
                    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {count} —Ñ–∞–π–ª–æ–≤")

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                continue

        if count >= LIMIT:
            break
    if count >= LIMIT:
        break

print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(texts)} –ø—Ä–∏–º–µ—Ä–æ–≤ PDG+COMPILER")

if len(texts) == 0:
    print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
    print("üîÑ –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º PDG...")

    test_codes = [
        """
def calculate_sum(a, b):
    result = a + b
    if result > 10:
        print("Large sum")
        return result * 2
    else:
        print("Small sum")
        return result
        """,

        """
class Calculator:
    def __init__(self, initial_value=0):
        self.value = initial_value

    def add(self, x):
        self.value += x
        return self.value

    def multiply(self, x):
        self.value *= x
        return self.value
        """,

        """
def process_data(data_list):
    results = []
    for item in data_list:
        if item is None:
            continue
        try:
            processed = item * 2
            results.append(processed)
        except Exception as e:
            print(f"Error processing {item}: {e}")
    return results
        """
    ]

    for i, code in enumerate(test_codes):
        seq = extract_pdg_sequence(code)
        if seq:
            texts.append({"content": seq})
            print(f"–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä {i+1}: {seq[:200]}...")

    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(texts)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å PDG")

# ---------------- 5. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ----------------
print("üî§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏...")
try:
    tokenizer = AutoTokenizer.from_pretrained(
        LOCAL_MODEL_DIR,
        trust_remote_code=True,
        local_files_only=True
    )

    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    print("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {e}")
    exit(1)

print("üî§ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
tokenized_data = []
for i, text in enumerate(texts):
    try:
        tokenized = tokenizer(
            text["content"],
            truncation=True,
            padding="max_length",
            max_length=MAX_LEN,
            return_tensors="pt"
        )
        tokenized["labels"] = tokenized["input_ids"].clone()
        tokenized_data.append(tokenized)

        if (i + 1) % 100 == 0:
            print(f"‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {i + 1} –ø—Ä–∏–º–µ—Ä–æ–≤")

    except Exception as e:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –ø—Ä–∏–º–µ—Ä
        continue

print(f"‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(tokenized_data)} –ø—Ä–∏–º–µ—Ä–æ–≤")

if len(tokenized_data) == 0:
    print("‚ùå –ù–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!")
    exit(1)

# ---------------- 7. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ ----------------
class PDGDataset(Dataset):
    def __init__(self, tokenized_data):
        self.tokenized_data = tokenized_data

    def __len__(self):
        return len(self.tokenized_data)

    def __getitem__(self, idx):
        item = self.tokenized_data[idx]
        return {
            'input_ids': item['input_ids'].squeeze(0),
            'attention_mask': item['attention_mask'].squeeze(0),
            'labels': item['labels'].squeeze(0)
        }

dataset = PDGDataset(tokenized_data)
print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω")

# ---------------- 8. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ ----------------
print("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏...")
# –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Qwen2ForCausalLM –∫–∞–∫ —Ä–∞–Ω—å—à–µ; –µ—Å–ª–∏ —É –≤–∞—Å –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å ‚Äî –∑–∞–º–µ–Ω–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –∫–ª–∞—Å—Å–æ–º.
try:
    from transformers import Qwen2ForCausalLM  # –µ—Å–ª–∏ trust_remote_code —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Ç–∞–∫–æ–π –∫–ª–∞—Å—Å
    ModelClass = Qwen2ForCausalLM
except Exception:
    ModelClass = AutoModelForCausalLM  # fallback

try:
    model = ModelClass.from_pretrained(
        LOCAL_MODEL_DIR,
        trust_remote_code=True,
        torch_dtype=torch.float16,
        device_map="auto",  # 'cuda' -> –∏—Å–ø–æ–ª—å–∑—É–µ–º auto, —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å
        local_files_only=True
    )
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å float16")

except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å float16: {e}")
    try:
        model = ModelClass.from_pretrained(
            LOCAL_MODEL_DIR,
            trust_remote_code=True,
            device_map="auto",
            local_files_only=True
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –±–µ–∑ float16")
    except Exception as e2:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e2}")
        exit(1)

# ---------------- 9. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA ----------------
print("üéõÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA...")
try:
    lora_config = LoraConfig(
        r=8,
        lora_alpha=32,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM"
    )

    model = get_peft_model(model, lora_config)
    # –ü–µ—á–∞—Ç—å —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–∞–µ–º—ã—Ö
    try:
        model.print_trainable_parameters()
    except Exception:
        pass
    print("‚úÖ LoRA –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LoRA: {e}")
    exit(1)

# ---------------- 10. –û–±—É—á–µ–Ω–∏–µ ----------------
print("üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è...")

training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=4,
    num_train_epochs=EPOCHS,
    learning_rate=LR,
    warmup_steps=50,
    logging_steps=10,
    save_steps=200,
    save_total_limit=1,
    fp16=torch.cuda.is_available() and getattr(model, "dtype", None) == torch.float16,
    dataloader_pin_memory=False,
    remove_unused_columns=False,
    report_to="none",
    disable_tqdm=False,
)

def simple_collate_fn(batch):
    return {
        'input_ids': torch.stack([item['input_ids'] for item in batch]),
        'attention_mask': torch.stack([item['attention_mask'] for item in batch]),
        'labels': torch.stack([item['labels'] for item in batch])
    }

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    data_collator=simple_collate_fn
)

print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ‚Ä¶")
try:
    trainer.train()
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")

# ---------------- 11. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ----------------
print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
try:
    trainer.save_model()
    tokenizer.save_pretrained(OUTPUT_DIR)
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {OUTPUT_DIR}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    test_input = "PDG: Function Assign BinOp If Compare Call Return COMPILER: OK"
    test_tokens = tokenizer(test_input, return_tensors="pt", max_length=MAX_LEN, truncation=True)
    if torch.cuda.is_available():
        test_tokens = {k: v.cuda() for k, v in test_tokens.items()}

    with torch.no_grad():
        outputs = model.generate(
            **test_tokens,
            max_length=80,
            do_sample=True,
            temperature=0.7,
            pad_token_id=tokenizer.eos_token_id
        )
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generated_text}")

except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

# –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
del model, trainer, dataset, tokenized_data
gc.collect()
if torch.cuda.is_available():
    torch.cuda.empty_cache()

print("üéâ –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")